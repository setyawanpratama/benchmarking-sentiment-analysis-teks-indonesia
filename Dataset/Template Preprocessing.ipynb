{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C/Users/User/Downloads/Time to Skripsi/benchmarking-sentiment-analysis-teks-indonesia/Preprocessing')\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import Sastrawi\n",
    "import os\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(series):\n",
    "    series = series.drop_duplicates()\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(series):\n",
    "    text = series.str.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text, removed_param):\n",
    "    if \"url\" not in removed_param:\n",
    "        text = re.sub(r'http\\S+ ', '', text)\n",
    "    if \"rt\" not in removed_param:\n",
    "        text = re.compile('RT @').sub('@', text, count=1).strip()\n",
    "    if \"username\" not in removed_param:\n",
    "        text= re.sub('@[^\\s]+',' ',text)\n",
    "    if \"emoticon\" not in removed_param:\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "#    if \"punctuation\" not in removed_param:\n",
    "#        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    if \"number\" not in removed_param:\n",
    "        text = re.sub(r'[0-9]+', ' ',  text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalisasi(tweet):\n",
    "    normal_tw = tweet.strip()\n",
    "    normal_regex = re.compile(r\"(.)\\1{1,}\")\n",
    "    normal_tw = normal_regex.sub(r\"\\1\\1\", normal_tw)\n",
    "    return normal_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('stopwords_ex.csv', header=None)[0].values\n",
    "\n",
    "def remove_stopwords(tweet):\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    token_afterremoval = []\n",
    "    for k in token:\n",
    "        if k not in stopwords:\n",
    "            token_afterremoval.append(k)\n",
    "\n",
    "    str_clean = ' '.join(token_afterremoval)\n",
    "    return str_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(tweet):\n",
    "    token = nltk.word_tokenize(tweet)\n",
    "    stem_kalimat = []\n",
    "    for k in token:\n",
    "        stem_kata = stemmer.stem(k)\n",
    "        stem_kalimat.append(stem_kata)\n",
    "\n",
    "    stem_kalimat_str = ' '.join(stem_kalimat)\n",
    "    return stem_kalimat_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andi', 'kerap', 'melakukan', 'transaksi', 'rutin', 'secara', 'daring', 'atau', 'online', '.']\n"
     ]
    }
   ],
   "source": [
    "def tokenization(teks):\n",
    "    from nltk.tokenize import word_tokenize \n",
    "\n",
    "    tokens = word_tokenize(teks)\n",
    "    return tokens\n",
    "\n",
    "kalimat = \"Andi kerap melakukan transaksi rutin secara daring atau online.\"\n",
    "print(tokenization(kalimat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Soal jln Jatibaru,polisi tdk bs GERTAK gubernur .Emangny polisi tdk ikut pmbhasan? Jgn berpolitik. Pengaturan wilayah,hak gubernur. Persoalan Tn Abang soal turun temurun.Pelik.Perlu kesabaran.[USERNAME][USERNAME] [URL]\n"
     ]
    }
   ],
   "source": [
    "print(cleansing('RT @saya 123123123132 https://ejournal.gunadarma.ac.id/index.php/infokom/article/view/2411/1965 Soal jln Jatibaru,polisi tdk bs GERTAK gubernur .Emangny polisi tdk ikut pmbhasan? Jgn berpolitik. Pengaturan wilayah,hak gubernur. Persoalan Tn Abang soal turun temurun.Pelik.Perlu kesabaran.[USERNAME][USERNAME] [URL]', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templated_posneg_Dataset_C_HT_4000.csv\n",
      "templated_posneg_KicauanBerlabel.csv\n",
      "templated_posneg_dataset_komentar_instagram_cyberbullying.csv\n",
      "templated_posneg_dataset_tweet_sentimen_tayangan_tv.csv\n",
      "templated_posneg_dataset_tweet_sentiment_cellular_service_provider.csv\n",
      "templated_posneg_dataset_tweet_sentiment_opini_film.csv\n",
      "templated_posneg_dataset_tweet_sentiment_pilkada_DKI_2017.csv\n",
      "templated_posneg_hotel.csv\n",
      "templated_posneg_id-apps-review-sentimentanalysis.csv\n",
      "templated_posneg_id-movie-review-sentimentanalysis.csv\n",
      "templated_posneg_raw_data_sentiment2.csv\n",
      "templated_posnegnet_tweetcleannew600-only.csv\n",
      "templated_posnegnet_tweets_tagged_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "filesnames = os.listdir(\"../Dataset/Raw\")\n",
    "filesnames = [f for f in filesnames if (f.lower().endswith(\".csv\"))]\n",
    "filesnames.sort()\n",
    "for i in filesnames:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templated_posneg_Dataset_C_HT_4000.csv\n",
      "templated_posneg_KicauanBerlabel.csv\n",
      "templated_posneg_dataset_komentar_instagram_cyberbullying.csv\n",
      "templated_posneg_dataset_tweet_sentimen_tayangan_tv.csv\n",
      "templated_posneg_dataset_tweet_sentiment_cellular_service_provider.csv\n",
      "templated_posneg_dataset_tweet_sentiment_opini_film.csv\n",
      "templated_posneg_dataset_tweet_sentiment_pilkada_DKI_2017.csv\n",
      "templated_posneg_hotel.csv\n",
      "templated_posneg_id-apps-review-sentimentanalysis.csv\n",
      "templated_posneg_id-movie-review-sentimentanalysis.csv\n",
      "templated_posneg_raw_data_sentiment2.csv\n",
      "templated_posnegnet_tweetcleannew600-only.csv\n",
      "templated_posnegnet_tweets_tagged_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in filesnames:\n",
    "    df = pd.read_csv(\"Raw/\" + filename, sep=\";;;\", engine='python')\n",
    "    print(filename)\n",
    "    df['teks'] = remove_duplicate(df['teks'])\n",
    "    df['teks'] = casefolding(df['teks'])\n",
    "    df['teks'] = df['teks'].apply(lambda x: cleansing(str(x), ''))\n",
    "    df['teks'] = df['teks'].apply(lambda x: normalisasi(str(x)))\n",
    "    df['teks'] = df['teks'].apply(lambda x: remove_stopwords(str(x)))\n",
    "    df['teks'] = df['teks'].apply(lambda x: stemming(str(x)))\n",
    "    df.dropna(subset = ['teks'], inplace=True)\n",
    "\n",
    "    df.to_csv(\"AL-P/\" + filename, header=True, index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
