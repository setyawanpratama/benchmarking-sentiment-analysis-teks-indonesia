{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from featureExtraction.tf.tf import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = [x for x in os.listdir(\"../Dataset/Clean\") if (x.lower().endswith(\".csv\"))]\n",
    "clean.sort()\n",
    "\n",
    "DATA_CLEAN = [\"../Dataset/Clean/\" + x for x in os.listdir(\"../Dataset/Clean\") if (x.lower().endswith(\".csv\"))]\n",
    "DATA_CLEAN.sort()\n",
    "len_clean = len(DATA_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_sg(filepath, hs, neg, vector_size):\n",
    "    df = pd.read_csv(filepath, delimiter=\";\", low_memory=False, header=0)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    model_path = './featureExtraction/word2vec/models_all/model_sg_{}_{}.model'.format('hs' if hs == 1 else 'neg', vector_size)\n",
    "    model_sg = Word2Vec.load(model_path)\n",
    "\n",
    "    word2vec_arr=[]\n",
    "    for row in df['teks'].tolist():\n",
    "        tweets = row.split(\" \")\n",
    "        row_mean_vector = (np.mean([model_sg.wv[terms] for terms in tweets], axis=0)).tolist()\n",
    "        if not (type(row_mean_vector) is list):\n",
    "            row_mean_vector = [float(0) for i in range(vector_size)]\n",
    "        word2vec_arr.append(row_mean_vector)\n",
    "\n",
    "    return np.array(word2vec_arr), df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "count = 1\n",
    "fail = 0\n",
    "\n",
    "f1_list = []\n",
    "acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1/13 (templated_posneg_Dataset_C_HT_4000.csv)\n",
      "Accuracy: 0.9792500000000001 (0.00952)\n",
      "F1-Score: 0.9791380276802085 (0.00960)\n",
      "FE Time: 0.5475368499755859 seconds\n",
      "CL time: 13.782914638519287 seconds\n",
      "================================================\n",
      "Running 2/13 (templated_posneg_KicauanBerlabel.csv)\n",
      "Accuracy: 0.9090833333333332 (0.05549)\n",
      "F1-Score: 0.9019297639210432 (0.05760)\n",
      "FE Time: 0.16784191131591797 seconds\n",
      "CL time: 1.9172873497009277 seconds\n",
      "================================================\n",
      "Running 3/13 (templated_posneg_dataset_komentar_instagram_cyberbullying.csv)\n",
      "Accuracy: 0.881842105263158 (0.06995)\n",
      "F1-Score: 0.8766609479944385 (0.07421)\n",
      "FE Time: 0.1706681251525879 seconds\n",
      "CL time: 0.5912024974822998 seconds\n",
      "================================================\n",
      "Running 4/13 (templated_posneg_dataset_tweet_sentimen_tayangan_tv.csv)\n",
      "Accuracy: 0.8674999999999999 (0.07462)\n",
      "F1-Score: 0.8594817507608429 (0.08202)\n",
      "FE Time: 0.14896512031555176 seconds\n",
      "CL time: 0.470104455947876 seconds\n",
      "================================================\n",
      "Running 5/13 (templated_posneg_dataset_tweet_sentiment_cellular_service_provider.csv)\n",
      "Accuracy: 0.8511904761904763 (0.09267)\n",
      "F1-Score: 0.8440083845463103 (0.09662)\n",
      "FE Time: 0.14127159118652344 seconds\n",
      "CL time: 0.314788818359375 seconds\n",
      "================================================\n",
      "Running 6/13 (templated_posneg_dataset_tweet_sentiment_opini_film.csv)\n",
      "Accuracy: 0.8444444444444447 (0.11584)\n",
      "F1-Score: 0.8178736582045406 (0.14902)\n",
      "FE Time: 0.1416938304901123 seconds\n",
      "CL time: 0.308208703994751 seconds\n",
      "================================================\n",
      "Running 7/13 (templated_posneg_dataset_tweet_sentiment_pilkada_DKI_2017.csv)\n",
      "Accuracy: 0.7548989898989898 (0.05795)\n",
      "F1-Score: 0.7532296695636551 (0.05767)\n",
      "FE Time: 0.20753145217895508 seconds\n",
      "CL time: 1.7588229179382324 seconds\n",
      "================================================\n",
      "Running 8/13 (templated_posneg_hotel.csv)\n",
      "Accuracy: 0.9154831663326654 (0.01104)\n",
      "F1-Score: 0.9153394584812077 (0.01112)\n",
      "FE Time: 1.9115490913391113 seconds\n",
      "CL time: 111.65730047225952 seconds\n",
      "================================================\n",
      "Running 9/13 (templated_posneg_id-apps-review-sentimentanalysis.csv)\n",
      "Accuracy: 0.875 (0.08292)\n",
      "F1-Score: 0.8522810073913016 (0.09558)\n",
      "FE Time: 0.15579628944396973 seconds\n",
      "CL time: 0.18405508995056152 seconds\n",
      "================================================\n",
      "Running 10/13 (templated_posneg_id-movie-review-sentimentanalysis.csv)\n",
      "Accuracy: 0.6960000000000001 (0.10307)\n",
      "F1-Score: 0.6895229222065308 (0.10369)\n",
      "FE Time: 0.17100954055786133 seconds\n",
      "CL time: 0.9642531871795654 seconds\n",
      "================================================\n",
      "Running 11/13 (templated_posneg_raw_data_sentiment2.csv)\n",
      "Accuracy: 0.8500291879270085 (0.01555)\n",
      "F1-Score: 0.8462411000598102 (0.01554)\n",
      "FE Time: 1.2761001586914062 seconds\n",
      "CL time: 91.4764084815979 seconds\n",
      "================================================\n",
      "Running 12/13 (templated_posnegnet_tweetcleannew600-only.csv)\n",
      "Accuracy: 0.6071855921855921 (0.03590)\n",
      "F1-Score: 0.604539802365617 (0.03541)\n",
      "FE Time: 0.4188873767852783 seconds\n",
      "CL time: 15.855684041976929 seconds\n",
      "================================================\n",
      "Running 13/13 (templated_posnegnet_tweets_tagged_preprocessed.csv)\n",
      "Accuracy: 0.7714166666666668 (0.06381)\n",
      "F1-Score: 0.5959695702251244 (0.10741)\n",
      "FE Time: 0.16938543319702148 seconds\n",
      "CL time: 1.1094377040863037 seconds\n",
      "================================================\n",
      "================================================\n",
      "Overall Accuracy = 0.8310249201724874 (0.09594693298326261)\n",
      "Overall F1-Score = 0.8104781587231253 (0.11270263419275042)\n",
      "Failed = 0/13\n"
     ]
    }
   ],
   "source": [
    "for i in DATA_CLEAN:\n",
    "    try:\n",
    "        print(\"Running {}/{} ({})\".format(count, len_clean, clean[count-1]))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Feature Extraction\n",
    "        result_fe1, label = term_freq(i)\n",
    "        result_fe2, label = word2vec_sg(i, 1, 0, 300)\n",
    "        result_fe = np.concatenate((result_fe1, result_fe2), axis=1)\n",
    "        fe_time = time.time()\n",
    "\n",
    "        # prepare classifier\n",
    "        cv = KFold(n_splits=20, random_state=1, shuffle=True)\n",
    "        logRes = LogisticRegression(random_state=1, max_iter=10000)\n",
    "        \n",
    "        # prepare the cross-validation procedure\n",
    "        acc_score = cross_val_score(logRes, result_fe, label, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "        f1_score = cross_val_score(logRes, result_fe, label, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "        cl_time = time.time()\n",
    "\n",
    "        print('Accuracy: {} ({:.5f})'.format(np.mean(acc_score), np.std(acc_score)))\n",
    "        print('F1-Score: {} ({:.5f})'.format(np.mean(f1_score), np.std(f1_score)))\n",
    "        print('FE Time: {} seconds'.format(fe_time - start_time))\n",
    "        print('CL time: {} seconds'.format(cl_time - fe_time))\n",
    "        \n",
    "        f1_list.append(np.mean(f1_score))\n",
    "        acc_list.append(np.mean(acc_score))\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        count += 1\n",
    "        fail += 1\n",
    "        print(i, \": \", e)\n",
    "        pass\n",
    "    print(\"================================================\")\n",
    "\n",
    "print(\"================================================\")\n",
    "print(\"Overall Accuracy = {} ({})\".format(sum(acc_list)/len(acc_list), np.std(acc_list)))\n",
    "print(\"Overall F1-Score = {} ({})\".format(sum(f1_list)/len(f1_list), np.std(f1_list)))\n",
    "print(\"Failed = {}/{}\".format(fail, len_clean))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
