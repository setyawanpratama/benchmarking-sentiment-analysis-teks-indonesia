{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from featureExtraction.pos.postag import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = [x for x in os.listdir(\"../Dataset/Clean\") if (x.lower().endswith(\".csv\"))]\n",
    "clean.sort()\n",
    "\n",
    "DATA_CLEAN = [\"../Dataset/Clean/\" + x for x in os.listdir(\"../Dataset/Clean\") if (x.lower().endswith(\".csv\"))]\n",
    "DATA_CLEAN.sort()\n",
    "len_clean = len(DATA_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_sg(filepath, hs, neg, vector_size):\n",
    "    df = pd.read_csv(filepath, delimiter=\";\", low_memory=False, header=0)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    model_path = './featureExtraction/word2vec/models_all/model_sg_{}_{}.model'.format('hs' if hs == 1 else 'neg', vector_size)\n",
    "    model_sg = Word2Vec.load(model_path)\n",
    "\n",
    "    word2vec_arr=[]\n",
    "    for row in df['teks'].tolist():\n",
    "        tweets = row.split(\" \")\n",
    "        row_mean_vector = (np.mean([model_sg.wv[terms] for terms in tweets], axis=0)).tolist()\n",
    "        if not (type(row_mean_vector) is list):\n",
    "            row_mean_vector = [float(0) for i in range(vector_size)]\n",
    "        word2vec_arr.append(row_mean_vector)\n",
    "\n",
    "    return np.array(word2vec_arr), df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "count = 1\n",
    "fail = 0\n",
    "\n",
    "f1_list = []\n",
    "acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1/13 (templated_posneg_Dataset_C_HT_4000.csv)\n",
      "Accuracy: 0.9557499999999998 (0.01477)\n",
      "F1-Score: 0.9555818190730581 (0.01483)\n",
      "FE Time: 0.6767807006835938 seconds\n",
      "CL time: 2.7934324741363525 seconds\n",
      "================================================\n",
      "Running 2/13 (templated_posneg_KicauanBerlabel.csv)\n",
      "Accuracy: 0.8324166666666667 (0.06595)\n",
      "F1-Score: 0.819533760959354 (0.06922)\n",
      "FE Time: 0.21513700485229492 seconds\n",
      "CL time: 1.606637716293335 seconds\n",
      "================================================\n",
      "Running 3/13 (templated_posneg_dataset_komentar_instagram_cyberbullying.csv)\n",
      "Accuracy: 0.8688157894736843 (0.07407)\n",
      "F1-Score: 0.8643757973230312 (0.07656)\n",
      "FE Time: 0.18947267532348633 seconds\n",
      "CL time: 0.11362838745117188 seconds\n",
      "================================================\n",
      "Running 4/13 (templated_posneg_dataset_tweet_sentimen_tayangan_tv.csv)\n",
      "Accuracy: 0.8400000000000001 (0.07681)\n",
      "F1-Score: 0.8331269512458098 (0.08076)\n",
      "FE Time: 0.15558147430419922 seconds\n",
      "CL time: 0.11304736137390137 seconds\n",
      "================================================\n",
      "Running 5/13 (templated_posneg_dataset_tweet_sentiment_cellular_service_provider.csv)\n",
      "Accuracy: 0.7700000000000001 (0.10535)\n",
      "F1-Score: 0.7550032312029216 (0.10658)\n",
      "FE Time: 0.14249897003173828 seconds\n",
      "CL time: 0.09307336807250977 seconds\n",
      "================================================\n",
      "Running 6/13 (templated_posneg_dataset_tweet_sentiment_opini_film.csv)\n",
      "Accuracy: 0.783888888888889 (0.13515)\n",
      "F1-Score: 0.7570074614927556 (0.16152)\n",
      "FE Time: 0.2256612777709961 seconds\n",
      "CL time: 0.07683253288269043 seconds\n",
      "================================================\n",
      "Running 7/13 (templated_posneg_dataset_tweet_sentiment_pilkada_DKI_2017.csv)\n",
      "Accuracy: 0.7226262626262627 (0.07211)\n",
      "F1-Score: 0.7192551755940418 (0.07289)\n",
      "FE Time: 0.24385976791381836 seconds\n",
      "CL time: 0.32056188583374023 seconds\n",
      "================================================\n",
      "Running 8/13 (templated_posneg_hotel.csv)\n",
      "Accuracy: 0.8795298597194389 (0.01553)\n",
      "F1-Score: 0.8793714703392725 (0.01557)\n",
      "FE Time: 2.162785530090332 seconds\n",
      "CL time: 3.322861433029175 seconds\n",
      "================================================\n",
      "Running 9/13 (templated_posneg_id-apps-review-sentimentanalysis.csv)\n",
      "Accuracy: 0.8800000000000001 (0.10770)\n",
      "F1-Score: 0.8597091103341101 (0.12771)\n",
      "FE Time: 0.13139772415161133 seconds\n",
      "CL time: 0.08126449584960938 seconds\n",
      "================================================\n",
      "Running 10/13 (templated_posneg_id-movie-review-sentimentanalysis.csv)\n",
      "Accuracy: 0.674 (0.08697)\n",
      "F1-Score: 0.6675571269095445 (0.08547)\n",
      "FE Time: 0.17528414726257324 seconds\n",
      "CL time: 0.30310487747192383 seconds\n",
      "================================================\n",
      "Running 11/13 (templated_posneg_raw_data_sentiment2.csv)\n",
      "Accuracy: 0.7665200063420681 (0.01813)\n",
      "F1-Score: 0.7620266924024356 (0.01795)\n",
      "FE Time: 1.3386006355285645 seconds\n",
      "CL time: 3.3765170574188232 seconds\n",
      "================================================\n",
      "Running 12/13 (templated_posnegnet_tweetcleannew600-only.csv)\n",
      "Accuracy: 0.6004700854700854 (0.04435)\n",
      "F1-Score: 0.5964076784313274 (0.04330)\n",
      "FE Time: 0.4303476810455322 seconds\n",
      "CL time: 1.8118207454681396 seconds\n",
      "================================================\n",
      "Running 13/13 (templated_posnegnet_tweets_tagged_preprocessed.csv)\n",
      "Accuracy: 0.7697499999999999 (0.06437)\n",
      "F1-Score: 0.602959742340176 (0.12898)\n",
      "FE Time: 0.15787744522094727 seconds\n",
      "CL time: 0.46151137351989746 seconds\n",
      "================================================\n",
      "================================================\n",
      "Overall Accuracy = 0.7956744276297765 (0.09156615899800875)\n",
      "Overall F1-Score = 0.7747627705882952 (0.10416871055221613)\n",
      "Failed = 0/13\n"
     ]
    }
   ],
   "source": [
    "for i in DATA_CLEAN:\n",
    "    try:\n",
    "        print(\"Running {}/{} ({})\".format(count, len_clean, clean[count-1]))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Feature Extraction\n",
    "        result_fe1, label = run_postag(i)\n",
    "        result_fe2, label = word2vec_sg(i, 1, 0, 300)\n",
    "        result_fe = np.concatenate((result_fe1, result_fe2), axis=1)\n",
    "        fe_time = time.time()\n",
    "\n",
    "        # prepare classifier\n",
    "        cv = KFold(n_splits=20, random_state=1, shuffle=True)\n",
    "        logRes = LogisticRegression(random_state=1, max_iter=10000)\n",
    "        \n",
    "        # prepare the cross-validation procedure\n",
    "        acc_score = cross_val_score(logRes, result_fe, label, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "        f1_score = cross_val_score(logRes, result_fe, label, scoring='f1_macro', cv=cv, n_jobs=-1)\n",
    "        cl_time = time.time()\n",
    "\n",
    "        print('Accuracy: {} ({:.5f})'.format(np.mean(acc_score), np.std(acc_score)))\n",
    "        print('F1-Score: {} ({:.5f})'.format(np.mean(f1_score), np.std(f1_score)))\n",
    "        print('FE Time: {} seconds'.format(fe_time - start_time))\n",
    "        print('CL time: {} seconds'.format(cl_time - fe_time))\n",
    "        \n",
    "        f1_list.append(np.mean(f1_score))\n",
    "        acc_list.append(np.mean(acc_score))\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        count += 1\n",
    "        fail += 1\n",
    "        print(i, \": \", e)\n",
    "        pass\n",
    "    print(\"================================================\")\n",
    "\n",
    "print(\"================================================\")\n",
    "print(\"Overall Accuracy = {} ({})\".format(sum(acc_list)/len(acc_list), np.std(acc_list)))\n",
    "print(\"Overall F1-Score = {} ({})\".format(sum(f1_list)/len(f1_list), np.std(f1_list)))\n",
    "print(\"Failed = {}/{}\".format(fail, len_clean))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
