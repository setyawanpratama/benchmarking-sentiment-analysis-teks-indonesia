{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "from nltk.util import usage\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from featureExtraction.tf.tf import *\n",
    "from featureExtraction.tfidf.tfidf import *\n",
    "from featureExtraction.fasttext.fasttext import *\n",
    "from featureExtraction.lexicon.lexicon import *\n",
    "from featureExtraction.orthography.orthography import *\n",
    "from featureExtraction.pos.postag import *\n",
    "from featureExtraction.tf.tf import *\n",
    "from featureExtraction.word2vec.word2vec import *\n",
    "from featureExtraction.ngram.ngram import *\n",
    "\n",
    "from featureSelection.kFold import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = [x for x in os.listdir(\"./Dataset/clean\")]\n",
    "clean.sort()\n",
    "\n",
    "DATA_CLEAN = [\"./Dataset/clean/\" + x for x in os.listdir(\"./Dataset/clean\")]\n",
    "DATA_CLEAN.sort()\n",
    "len_clean = len(DATA_CLEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in DATA_CLEAN:\n",
    "    df = pd.read_csv(i, delimiter=\";\", low_memory=False, header=0)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    for tweet in df[\"teks\"].tolist():\n",
    "        list_kata = eval(tweet)\n",
    "        data.append(list_kata)\n",
    "\n",
    "model_cbow_hs_100 = Word2Vec(data, min_count=1, window=5, hs=1, negative=0, vector_size=100)\n",
    "model_cbow_hs_100.save('./featureExtraction/word2vec/models_all/model_cbow_hs_100.model')\n",
    "\n",
    "model_cbow_neg_100 = Word2Vec(data, min_count=1, window=5, hs=0, negative=5, vector_size=100)\n",
    "model_cbow_neg_100.save('./featureExtraction/word2vec/models_all/model_cbow_neg_100.model')\n",
    "\n",
    "model_cbow_hs_200 = Word2Vec(data, min_count=1, window=5, hs=1, negative=0, vector_size=200)\n",
    "model_cbow_hs_200.save('./featureExtraction/word2vec/models_all/model_cbow_hs_200.model')\n",
    "\n",
    "model_cbow_neg_200 = Word2Vec(data, min_count=1, window=5, hs=0, negative=5, vector_size=200)\n",
    "model_cbow_neg_200.save('./featureExtraction/word2vec/models_all/model_cbow_neg_200.model')\n",
    "\n",
    "model_cbow_hs_300 = Word2Vec(data, min_count=1, window=5, hs=1, negative=0, vector_size=300)\n",
    "model_cbow_hs_300.save('./featureExtraction/word2vec/models_all/model_cbow_hs_300.model')\n",
    "\n",
    "model_cbow_neg_300 = Word2Vec(data, min_count=1, window=5, hs=0, negative=5, vector_size=300)\n",
    "model_cbow_neg_300.save('./featureExtraction/word2vec/models_all/model_cbow_neg_300.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_cbow(filepath, hs, neg, vector_size):\n",
    "    df = pd.read_csv(filepath, delimiter=\";\", low_memory=False, header=0)\n",
    "    model_path = './featureExtraction/word2vec/models_all/model_cbow_{}_{}.model'.format('hs' if hs == 1 else 'neg', vector_size)\n",
    "    model_cbow = Word2Vec.load(model_path)\n",
    "\n",
    "    word2vec_arr=[]\n",
    "    for row in df['teks'].tolist():\n",
    "        tweets = eval(row)\n",
    "        row_mean_vector = (np.mean([model_cbow.wv[terms] for terms in tweets], axis=0)).tolist()\n",
    "        if not (type(row_mean_vector) is list):\n",
    "            row_mean_vector = [float(0) for i in range(vector_size)]\n",
    "        word2vec_arr.append(row_mean_vector)\n",
    "\n",
    "    return np.array(word2vec_arr), df['label'].tolist()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner with Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1/20 F1-score: 0.889 (0.096)\n",
      "Running 2/20 F1-score: 0.775 (0.089)\n",
      "Running 3/20 F1-score: 0.925 (0.015)\n",
      "Running 4/20 F1-score: 0.676 (0.084)\n",
      "Running 5/20 F1-score: 0.740 (0.023)\n",
      "Running 6/20 F1-score: 0.891 (0.017)\n",
      "Running 7/20 F1-score: 0.713 (0.113)\n",
      "Running 8/20 F1-score: 0.715 (0.105)\n",
      "Running 9/20 F1-score: 0.649 (0.138)\n",
      "Running 10/20 F1-score: 0.618 (0.185)\n",
      "Running 11/20 F1-score: 0.684 (0.087)\n",
      "Running 12/20 F1-score: 0.795 (0.147)\n",
      "Running 13/20 F1-score: 0.590 (0.086)\n",
      "Running 14/20 F1-score: 0.737 (0.129)\n",
      "Running 15/20 F1-score: 0.665 (0.054)\n",
      "Running 16/20 F1-score: 0.723 (0.020)\n",
      "Running 17/20 F1-score: 0.564 (0.033)\n",
      "Running 18/20 F1-score: 0.564 (0.033)\n",
      "Running 19/20 F1-score: 0.558 (0.055)\n",
      "Running 20/20 F1-score: 0.740 (0.065)\n",
      "0.7103841175239662\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "score_list = []\n",
    "count = 1\n",
    "fail = 0\n",
    "# for i in DATA_CLEAN:\n",
    "for i in DATA_CLEAN:\n",
    "    print(\"Running {}/{}\".format(count, len_clean), end=\" \")\n",
    "    try:\n",
    "        # timer mulai\n",
    "        result_fe, label = word2vec_cbow(i, 0, 5, 300)\n",
    "\n",
    "        # create dataset\n",
    "        # X, y = make_classification(n_samples=len(result_fe), n_features=len(result_fe[0]), random_state=1)\n",
    "        # prepare the cross-validation procedure\n",
    "\n",
    "        cv = KFold(n_splits=20, random_state=1, shuffle=True)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(result_fe, label)\n",
    "                \n",
    "        logRes = LogisticRegression(random_state=1, max_iter=1000)\n",
    "        logRes.fit(x_train, y_train)\n",
    "        predictions = logRes.predict(x_test)\n",
    "        \n",
    "        scores = cross_val_score(logRes, result_fe, label, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "        print('F1-score: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "        score_list.append(mean(scores))\n",
    "        count += 1\n",
    "        # timer selesai\n",
    "    except Exception as e:\n",
    "        count += 1\n",
    "        fail += 1\n",
    "        print(i, \": \", e)\n",
    "        pass\n",
    "\n",
    "print((sum(score_list)/len(score_list)))\n",
    "print(\"Failed: {}\".format(fail))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
