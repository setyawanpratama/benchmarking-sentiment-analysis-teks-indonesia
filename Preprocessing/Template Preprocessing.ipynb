{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "sys.path.append('C/Users/User/Downloads/Time to Skripsi/benchmarking-sentiment-analysis-teks-indonesia/Preprocessing')\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test reading csv\n",
    "#df = pd.read_csv(\"../Dataset/raw/Twitter_Emotion_Dataset.csv\",\n",
    "#                       delimiter=\",\", engine ='python',encoding=\"Latin-1\")\n",
    "#df = pd.read_csv(\"../Dataset/templated/templated_posneg_raw_data_sentiment2.csv\",\n",
    "#                       delimiter=\";;;\", engine ='python',encoding=\"utf-8-sig\")\n",
    "\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(series):\n",
    "    #removing any duplicates\n",
    "    series = series.drop_duplicates()\n",
    "    print(series)\n",
    "    return series\n",
    "#df = remove_duplicate(df)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(series):\n",
    "    #turn all letter to lowercase\n",
    "    series = series.str.casefold()\n",
    "    return series\n",
    "\n",
    "#df[\"teks\"]] = casefolding(df[\"teks\"]])\n",
    "#print(df[\"teks\"]])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text, removed_param):\n",
    "    #leave removed_param empty to use all cleansing\n",
    "    if \"url\" not in removed_param:\n",
    "        text = re.sub(r'http\\S+ ', '', text)\n",
    "    if \"rt\" not in removed_param:\n",
    "        text = re.compile('RT @').sub('@', text, count=1).strip()\n",
    "    if \"username\" not in removed_param:\n",
    "        text= re.sub('@[^\\s]+',' ',text)\n",
    "    if \"emoticon\" not in removed_param:\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "    if \"punctuation\" not in removed_param:\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    if \"number\" not in removed_param:\n",
    "        text = re.sub(r'[0-9]+', ' ',  text)\n",
    "    if \"whitespace\" not in removed_param:\n",
    "        text = text.lstrip()\n",
    "    return text\n",
    "#print(cleansing('luv u :)  , text = game is on üî•','emoticon'))\n",
    "#df['teks] = df['teks].apply(cleansing, removed_param=[])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_stopwords(tweet):\n",
    "#    english stopword removal\n",
    "#    token = nltk.word_tokenize(tweet)\n",
    "#    token_afterremoval = []\n",
    "#    for k in token:\n",
    "#        if k not in stopwords and k not in special_list:\n",
    "#            token_afterremoval.append(k)\n",
    "\n",
    "#    str_clean = ' '.join(token_afterremoval)\n",
    "#    return str_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def stopwords_removal_indonesia(teks):\n",
    "    #stopword removal such as yang, untuk, pada\n",
    "    from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopword = factory.create_stop_word_remover()\n",
    "    stop = stopword.remove(teks)\n",
    "\n",
    "    return stop\n",
    "\n",
    "#teks = 'Dengan Menggunakan Python dan Library Sastrawi saya dapat melakukan proses Stopword Removal'\n",
    "#df['teks] = df['teks].apply(stopwords_removal_indonesia)\n",
    "#print(df[\"teks\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(teks):\n",
    "    # english stemming using nltk\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    token = nltk.word_tokenize(teks)\n",
    "\n",
    "    stem_kalimat = []\n",
    "    for k in token:\n",
    "        stem_kata = stemmer.stem(k)\n",
    "        stem_kalimat.append(stem_kata)\n",
    "\n",
    "    stem_kalimat_str = ' '.join(stem_kalimat)\n",
    "    return stem_kalimat_str\n",
    "\n",
    "#teks = 'Dengan Menggunakan Python dan Library Sastrawi saya dapat melakukan proses Stopword Removal'\n",
    "#print(stemming(teks))\n",
    "#df['teks] = df['teks].apply(stemming)\n",
    "#print(df[\"teks\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def stemming_sastrawi(teks):\n",
    "    # remove Inflection Suffixes (‚Äú-lah‚Äù, ‚Äú-kah‚Äù, ‚Äú-ku‚Äù, ‚Äú-mu‚Äù, atau ‚Äú-nya‚Äù),\n",
    "    # derivational suffix (imbuhan turunan -i, -kan, -an),\n",
    "    # derivational prefix (awalan turunan be-, di-, ke-, me-, pe-, se- dan te-.)\n",
    "    # using sastrawi's dict\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    return stemmer.stem(teks)\n",
    "\n",
    "#teks = 'Dengan Menggunakan Python dan Library Sastrawi saya dapat melakukan proses Stopword Removal'\n",
    "#print(stemming_sastrawi(teks))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# impor word_tokenize dari modul nltk\n",
    "def tokenization(teks):\n",
    "    from nltk.tokenize import word_tokenize \n",
    "\n",
    "    tokens = word_tokenize(teks)\n",
    "    return tokens\n",
    "\n",
    "#kalimat = \"Andi kerap melakukan transaksi rutin secara daring atau online.\"\n",
    "#print(tokenization(kalimat))\n",
    "#df['teks] = df['teks].apply(tokenization)\n",
    "#print(df[\"teks\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Dataset/templated/templated_posneg_raw_data_sentiment2.csv\n",
      "                                                   teks label\n",
      "0             memahami omnibus law a thread of threads      1\n",
      "1     contoh twit sependapat dg omnibus law dg bahas...     1\n",
      "2     buka ig liat explore isinya omnibus law mau ik...     1\n",
      "3     meski hanya pekerja di pt mencari cinta sejati...     1\n",
      "4     jujur aja soal omnibuslaw aku no comment dulu ...     1\n",
      "...                                                 ...   ...\n",
      "7453  bem se sumbar dan riau tolak omnibus law undan...     0\n",
      "7454  hayo para pakar idealis bangunlah dari tidur k...     0\n",
      "7455  sukak atau tidak demokrasi adalah system yang ...     0\n",
      "7456  sedih banget ya allah kenapa jd gini ekspetasi...     0\n",
      "7457  kasian yaaa kita para rakyat jelata dan kita p...     0\n",
      "\n",
      "[7458 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                   teks label\n",
      "0                 paham omnibus law a thread of threads     1\n",
      "1     contoh twit dapat dg omnibus law dg bahasa yg ...     1\n",
      "2     buka ig liat explore isi omnibus law mau ikut ...     1\n",
      "3     meski kerja pt cari cinta sejati tetep suara p...     1\n",
      "4     jujur aja soal omnibuslaw aku no comment dulu ...     1\n",
      "...                                                 ...   ...\n",
      "7453  bem se sumbar riau tolak omnibus law undang un...     0\n",
      "7454  hayo pakar idealis bangun tidur rakyat butuh b...     0\n",
      "7455  sukak tidak demokrasi system sedang pakai demo...     0\n",
      "7456  sedih banget allah jd gin ekspetasi omnibuslaw...     0\n",
      "7457  kasi yaaa rakyat jelata para mahasiswa yg aksi...     0\n",
      "\n",
      "[7431 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0           [paham, omnibus, law, a, thread, of, threads]\n",
      "1       [contoh, twit, dapat, dg, omnibus, law, dg, ba...\n",
      "2       [buka, ig, liat, explore, isi, omnibus, law, m...\n",
      "3       [meski, kerja, pt, cari, cinta, sejati, tetep,...\n",
      "4       [jujur, aja, soal, omnibuslaw, aku, no, commen...\n",
      "                              ...                        \n",
      "7453    [bem, se, sumbar, riau, tolak, omnibus, law, u...\n",
      "7454    [hayo, pakar, idealis, bangun, tidur, rakyat, ...\n",
      "7455    [sukak, tidak, demokrasi, system, sedang, paka...\n",
      "7456    [sedih, banget, allah, jd, gin, ekspetasi, omn...\n",
      "7457    [kasi, yaaa, rakyat, jelata, para, mahasiswa, ...\n",
      "Name: teks, Length: 7431, dtype: object\n",
      "../Dataset/clean/templated_posneg_raw_data_sentiment2.csv\n",
      "../Dataset/templated/templated_posneg_Twitter_Emotion_Dataset.csv\n",
      "                                                   teks label\n",
      "0     Kepingin gudeg mbarek Bu hj. Amad Foto dari go...     1\n",
      "1     Sharing pengalaman aja, kemarin jam 18.00 bata...     1\n",
      "2     Sharing sama temen tuh emg guna bgt. Disaat lu...     1\n",
      "3     sangat bersyukur bisa mendoakan kakeknya, Bung...     1\n",
      "4     Setiap kesempatan yg pernah hadir tuk dapat me...     1\n",
      "...                                                 ...   ...\n",
      "4399  Mengubah kebiasaan seseorang yg kurang baik it...     0\n",
      "4400  nah diam lebih bagus yaudah saya diam saja deh...     0\n",
      "4401  Sulitnya menetapkan Calon Wapresnya Jokowi di ...     0\n",
      "4402  5. masa depannya nggak jelas. lha iya, gimana ...     0\n",
      "4403  Ya Allah, hanya Engkau yang mengetahui rasa sa...     0\n",
      "\n",
      "[4404 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                   teks label\n",
      "0     kepingin gudeg mbarek bu hj amad foto google s...     1\n",
      "1     sharing alam aja kemarin jam     batalin tiket...     1\n",
      "2     sharing sama temen tuh emg bgt saat lu ngerasa...     1\n",
      "3     sangat syukur doa kakek bung karno sama anak y...     1\n",
      "4     sempat yg pernah hadir tuk buat selalu rasa am...     1\n",
      "...                                                 ...   ...\n",
      "4399  ubah biasa orang yg kurang baik itu berat mest...     0\n",
      "4400  nah diam lebih bagus yaudah diam deh     kepo ...     0\n",
      "4401  sulit tetap calon wapresnya jokowi pilpres   s...     0\n",
      "4402  masa depan jelas lha iya gimana mau jelas coba...     0\n",
      "4403  allah engkau tahu rasa sakit hati ini sembuh a...     0\n",
      "\n",
      "[4375 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0       [kepingin, gudeg, mbarek, bu, hj, amad, foto, ...\n",
      "1       [sharing, alam, aja, kemarin, jam, batalin, ti...\n",
      "2       [sharing, sama, temen, tuh, emg, bgt, saat, lu...\n",
      "3       [sangat, syukur, doa, kakek, bung, karno, sama...\n",
      "4       [sempat, yg, pernah, hadir, tuk, buat, selalu,...\n",
      "                              ...                        \n",
      "4399    [ubah, biasa, orang, yg, kurang, baik, itu, be...\n",
      "4400    [nah, diam, lebih, bagus, yaudah, diam, deh, k...\n",
      "4401    [sulit, tetap, calon, wapresnya, jokowi, pilpr...\n",
      "4402    [masa, depan, jelas, lha, iya, gimana, mau, je...\n",
      "4403    [allah, engkau, tahu, rasa, sakit, hati, ini, ...\n",
      "Name: teks, Length: 4375, dtype: object\n",
      "../Dataset/clean/templated_posneg_Twitter_Emotion_Dataset.csv\n",
      "../Dataset/templated/templated_posnegnet_data_total.csv\n",
      "                                                   teks  label\n",
      "0     jadi menteri pendidikan memang pusing banget s...   -1.0\n",
      "1     salah satu curhatan anak sma ngerasain sekolah...   -1.0\n",
      "2     ngga ada uang buat nabung karena ngga dapet ua...   -1.0\n",
      "3     ribet banget soalnya sekolah gue tuh absen mul...   -1.0\n",
      "4     sekarang mau sekolah ajaa cape kalo belajar on...   -1.0\n",
      "...                                                 ...    ...\n",
      "3467  maleh nak on dah tapi tula tu online class lak...   -1.0\n",
      "3468                      nyerah sm online class bgsatt   -1.0\n",
      "3469                          saya sanggup online class    1.0\n",
      "3470      online class ribet banget anjinf males bgt ak   -1.0\n",
      "3471                saya tak nak online class tapi tapi   -1.0\n",
      "\n",
      "[3472 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                   teks  label\n",
      "0     jadi menteri didik memang pusing banget sekara...   -1.0\n",
      "1     salah satu curhatan anak sma ngerasain sekolah...   -1.0\n",
      "2     ngga uang buat nabung ngga dapet uang jajan la...   -1.0\n",
      "3     ribet banget soal sekolah gue tuh absen mulai ...   -1.0\n",
      "4       sekarang mau sekolah ajaa cape kalo ajar online   -1.0\n",
      "...                                                 ...    ...\n",
      "3467     maleh nak on dah tula tu online class lak njir   -1.0\n",
      "3468                      nyerah sm online class bgsatt   -1.0\n",
      "3469                               sanggup online class    1.0\n",
      "3470      online class ribet banget anjinf males bgt ak   -1.0\n",
      "3471                          tak nak online class tapi   -1.0\n",
      "\n",
      "[3369 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0       [jadi, menteri, didik, memang, pusing, banget,...\n",
      "1       [salah, satu, curhatan, anak, sma, ngerasain, ...\n",
      "2       [ngga, uang, buat, nabung, ngga, dapet, uang, ...\n",
      "3       [ribet, banget, soal, sekolah, gue, tuh, absen...\n",
      "4       [sekarang, mau, sekolah, ajaa, cape, kalo, aja...\n",
      "                              ...                        \n",
      "3467    [maleh, nak, on, dah, tula, tu, online, class,...\n",
      "3468                  [nyerah, sm, online, class, bgsatt]\n",
      "3469                             [sanggup, online, class]\n",
      "3470    [online, class, ribet, banget, anjinf, males, ...\n",
      "3471                      [tak, nak, online, class, tapi]\n",
      "Name: teks, Length: 3369, dtype: object\n",
      "../Dataset/clean/templated_posnegnet_data_total.csv\n",
      "../Dataset/templated/templated_posnegnet_data_total_negpos.csv\n",
      "                                                   teks  label\n",
      "0     jadi menteri pendidikan memang pusing banget s...   -1.0\n",
      "1     salah satu curhatan anak sma ngerasain sekolah...   -1.0\n",
      "2     ngga ada uang buat nabung karena ngga dapet ua...   -1.0\n",
      "3     ribet banget soalnya sekolah gue tuh absen mul...   -1.0\n",
      "4     sekarang mau sekolah ajaa cape kalo belajar on...   -1.0\n",
      "...                                                 ...    ...\n",
      "3468  maleh nak on dah tapi tula tu online class lak...   -1.0\n",
      "3469                      nyerah sm online class bgsatt   -1.0\n",
      "3470                          saya sanggup online class    1.0\n",
      "3471      online class ribet banget anjinf males bgt ak   -1.0\n",
      "3472                saya tak nak online class tapi tapi   -1.0\n",
      "\n",
      "[3473 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                   teks  label\n",
      "0     jadi menteri didik memang pusing banget sekara...   -1.0\n",
      "1     salah satu curhatan anak sma ngerasain sekolah...   -1.0\n",
      "2     ngga uang buat nabung ngga dapet uang jajan la...   -1.0\n",
      "3     ribet banget soal sekolah gue tuh absen mulai ...   -1.0\n",
      "4       sekarang mau sekolah ajaa cape kalo ajar online   -1.0\n",
      "...                                                 ...    ...\n",
      "3468     maleh nak on dah tula tu online class lak njir   -1.0\n",
      "3469                      nyerah sm online class bgsatt   -1.0\n",
      "3470                               sanggup online class    1.0\n",
      "3471      online class ribet banget anjinf males bgt ak   -1.0\n",
      "3472                          tak nak online class tapi   -1.0\n",
      "\n",
      "[3369 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0       [jadi, menteri, didik, memang, pusing, banget,...\n",
      "1       [salah, satu, curhatan, anak, sma, ngerasain, ...\n",
      "2       [ngga, uang, buat, nabung, ngga, dapet, uang, ...\n",
      "3       [ribet, banget, soal, sekolah, gue, tuh, absen...\n",
      "4       [sekarang, mau, sekolah, ajaa, cape, kalo, aja...\n",
      "                              ...                        \n",
      "3468    [maleh, nak, on, dah, tula, tu, online, class,...\n",
      "3469                  [nyerah, sm, online, class, bgsatt]\n",
      "3470                             [sanggup, online, class]\n",
      "3471    [online, class, ribet, banget, anjinf, males, ...\n",
      "3472                      [tak, nak, online, class, tapi]\n",
      "Name: teks, Length: 3369, dtype: object\n",
      "../Dataset/clean/templated_posnegnet_data_total_negpos.csv\n",
      "../Dataset/templated/templated_posnegnet_Sentiment Data Joko Widodo.csv\n",
      "                                                  teks  label\n",
      "0                          oh nyata pocong pakai siri      -1\n",
      "1    nyamuk datang lah ada tanggal lah kakak ponti ...     -1\n",
      "2                  foto awkarin jadi poconggak sambung      0\n",
      "3    maklum kalau pocong banyak tanya kan di kubur ...      0\n",
      "4    benar aku tak larat sangat deh ini tapi sebab ...      1\n",
      "..                                                 ...    ...\n",
      "995  rt pocong sudah balik ke twitterawkarin sudah ...      0\n",
      "996  rt pocong sudah balik ke twitterawkarin sudah ...      0\n",
      "997  good job min kalo mau bikin meta sebar pocong ...      1\n",
      "998       rt lah pocong mah sudah hits duluan keleusss      0\n",
      "999  lu belum main twitter kali nderr pas jam jaya ...      0\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "1\n",
      "../Dataset/templated/templated_posnegnet_Sentiment Data Prabowo Subianto.csv\n",
      "                                                  teks  label\n",
      "0    rt benar yang justru dikuatirkan adalah selama...      1\n",
      "1    rt sejumlah orang yang nama diri bagai aktivis...      0\n",
      "2    rt benar yang justru dikuatirkan adalah selama...      1\n",
      "3    rt tentang prabowo subianto indonesia bisa bub...     -1\n",
      "4    rt indonesian presidential election map by reg...      1\n",
      "..                                                 ...    ...\n",
      "995  capres dan cawapres nomor urut prabowo subiant...     -1\n",
      "996  rt surabaya harap agar harap dua joko widodo d...      0\n",
      "997  rt pergi lagi pak banyak banget orang rusiax y...      0\n",
      "998  rt setelah tangkap oleh aparat polisi dukung c...      1\n",
      "999  saya percaya pak prabowo subianto itu orang ba...      1\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "1\n",
      "../Dataset/templated/templated_posnegnet_tweetcleannew600-only.csv\n",
      "                                                   teks  label\n",
      "0     Kata Indonesia tidak dihargai bangsa asing Ber...     -1\n",
      "1     Negara kita ngutang buat bngun infrastruktur y...     -1\n",
      "2     Masa tenang msih ngoceh aja ttp jokowi harga mati     -1\n",
      "3     Prabowo Sandi Sepakat Tak Ambil Gaji karena Ne...     -1\n",
      "4     Gak nginti Lu to dan si AbdillahToha juga gak ...     -1\n",
      "...                                                 ...    ...\n",
      "1810  Bismillah dilihat dari hasil debat malam ini p...      1\n",
      "1811  Luar biasa performa dan penjelasan Pak Jokowi ...      1\n",
      "1812  Wow ga ngambil gaji sedikitpun kalo jadi presi...      1\n",
      "1813  Tidak hanya utk keamanan negeri ini kemajuan e...      1\n",
      "1814  Ekonomi indonesia bisa tumbuh  karena pembangu...      1\n",
      "\n",
      "[1815 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                   teks  label\n",
      "0     kata indonesia harga bangsa asing berita pasti...     -1\n",
      "1     negara ngutang buat bngun infrastruktur udah d...     -1\n",
      "2     masa tenang msih ngoceh aja ttp jokowi harga mati     -1\n",
      "3     prabowo sandi sepakat tak ambil gaji negara se...     -1\n",
      "4     gak nginti lu to si abdillahtoha gak ngacaaa g...     -1\n",
      "...                                                 ...    ...\n",
      "1810  bismillah lihat hasil debat malam pasang prabo...      1\n",
      "1811  luar biasa performa jelas pak jokowi kh ma ruf...      1\n",
      "1812  wow ga ngambil gaji sedikit kalo jadi presiden...      1\n",
      "1813  hanya utk aman negeri maju ekonomi infrastrukt...      1\n",
      "1814  ekonomi indonesia tumbuh bangun infrastruktur ...      1\n",
      "\n",
      "[1810 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0       [kata, indonesia, harga, bangsa, asing, berita...\n",
      "1       [negara, ngutang, buat, bngun, infrastruktur, ...\n",
      "2       [masa, tenang, msih, ngoceh, aja, ttp, jokowi,...\n",
      "3       [prabowo, sandi, sepakat, tak, ambil, gaji, ne...\n",
      "4       [gak, nginti, lu, to, si, abdillahtoha, gak, n...\n",
      "                              ...                        \n",
      "1810    [bismillah, lihat, hasil, debat, malam, pasang...\n",
      "1811    [luar, biasa, performa, jelas, pak, jokowi, kh...\n",
      "1812    [wow, ga, ngambil, gaji, sedikit, kalo, jadi, ...\n",
      "1813    [hanya, utk, aman, negeri, maju, ekonomi, infr...\n",
      "1814    [ekonomi, indonesia, tumbuh, bangun, infrastru...\n",
      "Name: teks, Length: 1810, dtype: object\n",
      "../Dataset/clean/templated_posnegnet_tweetcleannew600-only.csv\n",
      "../Dataset/templated/templated_posnegnet_tweets_tagged_preprocessed.csv\n",
      "                                                  teks  label\n",
      "0    minimal sudah aku kabari juga belum bikin rili...     -1\n",
      "1    iya karena itu memang fitur untuk penjual yang...      0\n",
      "2    diduga bocor data juta pelanggan tokopedia dij...      0\n",
      "3    kemungkinan telah terjadi kebocoran data pengg...      0\n",
      "4    tokopedia tidak ada kebocoran data pengguna da...      1\n",
      "..                                                 ...    ...\n",
      "489  gak disangka data gua bocor di canva wattpad s...     -1\n",
      "490  dataku bocor di tokopedia sama wattpad tapi ak...      1\n",
      "491  tokopedia bocor dari april yang pas kasus hack...      0\n",
      "492  pas itu emang pernah deh dihari yg sama tokope...      0\n",
      "493  tapi katanya dataku bocor sama tokopedia pas a...      1\n",
      "\n",
      "[494 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "                                                  teks  label\n",
      "0    minimal aku kabar belum bikin rilis soal bocor...     -1\n",
      "1    iya memang fitur jual milik toko fisik biar ca...      0\n",
      "2    duga bocor data juta langgan tokopedia jual on...      0\n",
      "3                      mungkin jadi bocor data guna cc      0\n",
      "4    tokopedia ada bocor data guna data sebat data ...      1\n",
      "..                                                 ...    ...\n",
      "489  gak sangka data gua bocor canva wattpad sama t...     -1\n",
      "490  data bocor tokopedia sama wattpad aku gapernah...      1\n",
      "491     tokopedia bocor april pas kasus hack bukan sih      0\n",
      "492  pas emang pernah deh hari yg sama tokopedia bo...      0\n",
      "493  kata data bocor sama tokopedia pas april padah...      1\n",
      "\n",
      "[492 rows x 2 columns]\n",
      "1\n",
      "1\n",
      "0      [minimal, aku, kabar, belum, bikin, rilis, soa...\n",
      "1      [iya, memang, fitur, jual, milik, toko, fisik,...\n",
      "2      [duga, bocor, data, juta, langgan, tokopedia, ...\n",
      "3                 [mungkin, jadi, bocor, data, guna, cc]\n",
      "4      [tokopedia, ada, bocor, data, guna, data, seba...\n",
      "                             ...                        \n",
      "489    [gak, sangka, data, gua, bocor, canva, wattpad...\n",
      "490    [data, bocor, tokopedia, sama, wattpad, aku, g...\n",
      "491    [tokopedia, bocor, april, pas, kasus, hack, bu...\n",
      "492    [pas, emang, pernah, deh, hari, yg, sama, toko...\n",
      "493    [kata, data, bocor, sama, tokopedia, pas, apri...\n",
      "Name: teks, Length: 492, dtype: object\n",
      "../Dataset/clean/templated_posnegnet_tweets_tagged_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "# read the files name in list_csv\n",
    "list_csv = []\n",
    "\n",
    "for a in list_csv:\n",
    "    try:\n",
    "        read_csv = '../Dataset/templated/' + a +'.csv'\n",
    "        df = pd.read_csv(read_csv, delimiter=\";;;\", engine ='python',encoding=\"utf-8-sig\")\n",
    "\n",
    "        df.shape\n",
    "        print(read_csv)\n",
    "        print(df)\n",
    "        df[\"teks\"] = casefolding(df[\"teks\"])\n",
    "        print(\"1\")\n",
    "        df['teks'] = df['teks'].apply(stopwords_removal_indonesia)\n",
    "        print(\"1\")\n",
    "        df['teks'] = df['teks'].apply(stemming_sastrawi)\n",
    "        print(\"1\")\n",
    "        df['teks'] = df['teks'].apply(cleansing, removed_param=[])\n",
    "        print(\"1\")\n",
    "        df = remove_duplicate(df)\n",
    "        print(\"1\")\n",
    "        df['teks'] = df['teks'].apply(tokenization)\n",
    "        print(\"1\")\n",
    "        print(df[\"teks\"])\n",
    "\n",
    "        oiut_csv = '../Dataset/clean/' + a +'.csv'\n",
    "        print(oiut_csv)\n",
    "        df.to_csv(oiut_csv,sep = \";\")\n",
    "    except:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}