{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43fc256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca046db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Dataset/Split/Three_Label/train_posnegnet_tweetcleannew600-only.csv\", header=None, sep=';')\n",
    "valid_df = pd.read_csv(\"../Dataset/Split/Three_Label/valid_posnegnet_tweetcleannew600-only.csv\", header=None, sep=';')\n",
    "test_df = pd.read_csv(\"../Dataset/Split/Three_Label/test_posnegnet_tweetcleannew600-only.csv\", header=None, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3164485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negara ngutang bngun infrastruktur udah dipake...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tenang msih ngoceh aja ttp jokowi harga mati</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prabowo sandi sepakat ambil gaji negara susah</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gak nginti lu to si abdillahtoha gak ngacaa ga...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ummat islam yg waras cerdas senang amal coblos...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  negara ngutang bngun infrastruktur udah dipake... -1\n",
       "1       tenang msih ngoceh aja ttp jokowi harga mati -1\n",
       "2      prabowo sandi sepakat ambil gaji negara susah -1\n",
       "3  gak nginti lu to si abdillahtoha gak ngacaa ga... -1\n",
       "4  ummat islam yg waras cerdas senang amal coblos... -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [train_df, valid_df, test_df]\n",
    "df = pd.concat(frames, axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753d24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2] = [simple_preprocess(line, deacc=True) for line in df[0]]\n",
    "train_df[2] = [simple_preprocess(line, deacc=True) for line in train_df[0]]\n",
    "valid_df[2] = [simple_preprocess(line, deacc=True) for line in valid_df[0]]\n",
    "test_df[2] = [simple_preprocess(line, deacc=True) for line in test_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99dc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = df[2].map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73267d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../Machine Learning/featureExtraction/word2vec/models_all/model_sg_hs_300.model'\n",
    "model_sg = Word2Vec.load(model_path)\n",
    "\n",
    "words = list(model_sg.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86377a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24931\n"
     ]
    }
   ],
   "source": [
    "padding_idx = model_sg.wv.key_to_index.get('pad')\n",
    "\n",
    "def use_w2v(text):\n",
    "    vec = [padding_idx for i in range(max_len)]\n",
    "    i = 0\n",
    "    for word in text:\n",
    "        if word not in model_sg.wv.key_to_index.keys():\n",
    "            vec[i] = 0\n",
    "            print(word)\n",
    "        else:\n",
    "            vec[i] = model_sg.wv.key_to_index.get(word)\n",
    "        i += 1\n",
    "    return torch.tensor(vec, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0472c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, n_class):\n",
    "    if n_class == 2:\n",
    "        if label == 0:\n",
    "            return torch.tensor([0], dtype=torch.int64, device=device)\n",
    "        elif label == 1:\n",
    "            return torch.tensor([1], dtype=torch.int64, device=device)  \n",
    "    if n_class == 3:\n",
    "        if label == -1:\n",
    "            return torch.tensor([0], dtype=torch.int64, device=device)\n",
    "        elif label == 0:\n",
    "            return torch.tensor([1], dtype=torch.int64, device=device)\n",
    "        elif label == 1:\n",
    "            return torch.tensor([2], dtype=torch.int64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da40266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f50668e35e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d349bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, pretrained_embedding, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional,\n",
    "                 dropout_rate):\n",
    "        super().__init__()\n",
    "        w2v = Word2Vec.load(pretrained_embedding)\n",
    "        weights = w2v.wv\n",
    "        vocab_size = len(w2v.wv.key_to_index.keys())\n",
    "        pad_index = model_sg.wv.key_to_index.get('pad')\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(weights.vectors), padding_idx=model_sg.wv.key_to_index.get('pad'), freeze=False)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional,\n",
    "                            dropout=dropout_rate, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, ids):\n",
    "        embedded = self.dropout(self.embedding(ids))\n",
    "        packed_output, (hidden, cell) = self.lstm(embedded)\n",
    "        if self.lstm.bidirectional:\n",
    "            hidden = self.dropout(torch.cat([hidden[-1], hidden[-2]], dim=-1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1])\n",
    "        prediction = self.fc(hidden)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "965d6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(pretrained_embedding='../Machine Learning/featureExtraction/word2vec/models_all/model_sg_hs_300.model',\n",
    "            embedding_dim = 300,\n",
    "            hidden_dim = 300,\n",
    "            output_dim = 3,\n",
    "            n_layers = 2,\n",
    "            bidirectional = False,\n",
    "            dropout_rate =0.5)\n",
    "\n",
    "lstm.to(device)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9111502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=131221):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer, train, valid, num_class, epochs):\n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for index, row in train.iterrows():\n",
    "            model.zero_grad()\n",
    "\n",
    "            bow_vec = use_w2v(row[2])\n",
    "\n",
    "            probs = model(bow_vec)\n",
    "\n",
    "            target = make_target(train[1][index], num_class)\n",
    "\n",
    "            loss = loss_fn(probs, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = train_loss / len(train)\n",
    "\n",
    "        # After the completion of each training epoch, measure the model's\n",
    "        # performance on our validation set.\n",
    "        val_loss, val_accuracy = evaluate(model, valid, num_class)\n",
    "\n",
    "        # Track the best accuracy\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "\n",
    "        # Print performance over the entire training data\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "        print(f\"{epoch + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.4f} | {time_elapsed:^9.2f}\")\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "def evaluate(model, test, num_class):\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    for index, row in test.iterrows():\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            bow_vec = use_w2v(row[2])\n",
    "            logits = model(bow_vec)\n",
    "        \n",
    "        target = make_target(test[1][index], num_class)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, target)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        correct = (preds == target).cpu().numpy()[0]\n",
    "        val_accuracy.append(correct)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d6c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   0.202551   |  7.583991  |  0.1443   |   8.50   \n",
      "   2    |   0.226577   |  6.496914  |  0.1443   |   7.35   \n",
      "   3    |   0.233914   |  5.091451  |  0.1443   |   7.45   \n",
      "   4    |   0.258338   |  5.657870  |  0.1443   |   7.34   \n",
      "   5    |   0.244876   |  5.166702  |  0.1443   |   7.41   \n",
      "   6    |   0.258134   |  5.063616  |  0.1443   |   7.35   \n",
      "   7    |   0.274952   |  5.549274  |  0.1443   |   7.49   \n",
      "   8    |   0.262178   |  5.766788  |  0.1443   |   7.22   \n",
      "   9    |   0.243232   |  6.174631  |  0.1443   |   7.20   \n",
      "  10    |   0.235021   |  6.090920  |  0.1443   |   7.37   \n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 0.14%.\n"
     ]
    }
   ],
   "source": [
    "set_seed(131221)\n",
    "train(lstm, optimizer, train_df, valid_df, epochs=10, num_class = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83666c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       107\n",
      "           1     0.0000    0.0000    0.0000       127\n",
      "           2     0.3536    1.0000    0.5224       128\n",
      "\n",
      "    accuracy                         0.3536       362\n",
      "   macro avg     0.1179    0.3333    0.1741       362\n",
      "weighted avg     0.1250    0.3536    0.1847       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "bow_cnn_predictions = []\n",
    "original_lables_cnn_bow = []\n",
    "lstm.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index, row in test_df.iterrows():\n",
    "        bow_vec = use_w2v(row[2])\n",
    "        probs = lstm(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        bow_cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        original_lables_cnn_bow.append(make_target(test_df[1][index], 3).cpu().numpy()[0])\n",
    "print(classification_report(original_lables_cnn_bow,bow_cnn_predictions, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
